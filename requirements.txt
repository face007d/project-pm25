from flask import Flask, request, jsonify
from flask_cors import CORS
import numpy as np
import joblib
import os
from tensorflow.keras.models import load_model

app = Flask(__name__)
# อนุญาตให้ Domain อื่น (Vercel) เข้าถึง API นี้ได้
CORS(app) 

# ดึงค่า PORT จาก Environment Variable ที่ Render กำหนดให้
port = int(os.environ.get("PORT", 5000))

# ระบุชื่อไฟล์ให้ตรงกับบน GitHub
# หากไฟล์อยู่ในโฟลเดอร์ย่อย ต้องระบุ path ให้ถูกต้อง เช่น 'backend/scaler (2).pkl'
model_name = 'lstm_pm25_model (2).h5'
scaler_name = 'scaler (2).pkl'

# ค้นหาตำแหน่งไฟล์ปัจจุบันเพื่อให้โหลดไฟล์ได้ถูกต้องไม่ว่าจะรันจากที่ไหน
base_path = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_path, model_name)
scaler_path = os.path.join(base_path, scaler_name)

model = None
scaler = None

# โหลดโมเดลเพียงครั้งเดียวตอนเริ่ม Server เพื่อประสิทธิภาพ
def init_model():
    global model, scaler
    if os.path.exists(model_path) and os.path.exists(scaler_path):
        try:
            model = load_model(model_path)
            scaler = joblib.load(scaler_path)
            print("✅ Model and Scaler loaded successfully!")
        except Exception as e:
            print(f"❌ Error loading files: {e}")
    else:
        print(f"❌ Error: Missing files at {model_path} or {scaler_path}")
        # แสดงรายการไฟล์ที่มีอยู่จริงในระบบเพื่อช่วย Debug
        print(f"Available files in current directory: {os.listdir(base_path)}")

init_model()

@app.route('/')
def home():
    status = "Ready" if model else "Model Missing"
    return f"PM2.5 Nakhon Phanom API is Running! (Status: {status})"

@app.route('/predict', methods=['POST'])
def predict():
    if model is None or scaler is None:
        return jsonify({'error': 'Server model is not loaded'}), 500
        
    try:
        data = request.get_json()
        if not data or 'inputs' not in data:
            return jsonify({'error': 'No input data provided'}), 400
            
        # รับข้อมูล 3 วันล่าสุด [v1, v2, v3]
        inputs = np.array(data['inputs']).reshape(-1, 1)
        
        # 1. Pre-processing (Scale ข้อมูล)
        input_scaled = scaler.transform(inputs)
        
        # 2. ปรับรูปทรงให้เข้ากับ LSTM (1 sample, 3 time steps, 1 feature)
        X_input = np.reshape(input_scaled, (1, 3, 1))
        
        # 3. Prediction
        prediction_scaled = model.predict(X_input, verbose=0)
        
        # 4. Inverse Transform กลับเป็นค่าฝุ่นจริง
        prediction_final = scaler.inverse_transform(prediction_scaled)
        
        return jsonify({
            'prediction': float(prediction_final[0][0]),
            'unit': 'µg/m3',
            'status': 'success'
        })
    except Exception as e:
        return jsonify({'error': f"Prediction failed: {str(e)}"}), 400

if __name__ == '__main__':
    # รันโดยใช้ host 0.0.0.0 และปิด debug mode เมื่อใช้งานจริงบนเซิร์ฟเวอร์
    app.run(host='0.0.0.0', port=port, debug=False)
